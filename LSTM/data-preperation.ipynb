{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "88799b8b-9fe5-49d3-94ac-4db26f61da46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2023.12.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch)\n",
      "  Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "Successfully installed filelock-3.16.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 triton-3.1.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install textblob\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eecedc4d-4f15-4127-a38b-338cea10d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from textblob import TextBlob\n",
    "import shutil\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5da748-f6cb-421c-a345-7fc4cbd70c5e",
   "metadata": {},
   "source": [
    "# Adding original files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d9e4f4d-ece4-4fe7-b855-2a7b9da13e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files copied successfully!\n"
     ]
    }
   ],
   "source": [
    "source_dir = '../Dataset/price/raw/'\n",
    "destination_dir = 'preprocessed-data/input-data/'\n",
    "\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.endswith('.csv'):\n",
    "        source_file = os.path.join(source_dir, filename)\n",
    "        destination_file = os.path.join(destination_dir, filename)\n",
    "        \n",
    "        shutil.copy2(source_file, destination_file)\n",
    "\n",
    "print(\"All files copied successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec1d035-40cd-44da-a119-18892bb00213",
   "metadata": {},
   "source": [
    "# Adding twitter sentiment and target value\n",
    "Analyzing tweet messages and outputting either 1 (positive), 0 (neutral) or -1 (negative) for each day per stock. Also adding the cumulative value with a penalty of 0.5 for neutral messages.\n",
    "Thanks to this jupyter for part of the code:\n",
    "\n",
    "https://github.com/mrizwan18/Stock-Prediction-usingTwitter-sentimental-analysis-and-CNN/blob/master/Stock-Predictor.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c463775-a3f5-457e-a6bc-103023c9c260",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_stocks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dates\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m## Looping through all stocks\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stock_file \u001b[38;5;129;01min\u001b[39;00m \u001b[43minput_stocks\u001b[49m:\n\u001b[1;32m     14\u001b[0m     stock_name \u001b[38;5;241m=\u001b[39m stock_file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     15\u001b[0m     source_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(source_dir, stock_file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_stocks' is not defined"
     ]
    }
   ],
   "source": [
    "def date_range(start_date, end_date):\n",
    "    start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    delta = timedelta(days=1)\n",
    "    dates = []\n",
    "    while start <= end:\n",
    "        dates.append(start.strftime(\"%Y-%m-%d\"))\n",
    "        start += delta\n",
    "    return dates\n",
    "\n",
    "stock_sentiments = {}\n",
    "\n",
    "for stock_dir in glob.glob(\"../Dataset/tweet/raw/*\"):\n",
    "    stock_name = os.path.basename(stock_dir)\n",
    "    stock_sentiments[stock_name] = []\n",
    "\n",
    "    for file in glob.glob(f\"{stock_dir}/*\"):\n",
    "        name = file.split(\"/\")[-1]\n",
    "        date_str = name.split(\".\")[0]\n",
    "        tweets = []\n",
    "\n",
    "        ## Twitter sentiment\n",
    "        with open(file, \"r\") as infile:\n",
    "            for line in infile:\n",
    "                t = json.loads(line)\n",
    "                tweet = {\"text\": t[\"text\"], \"weight\": t[\"favorite_count\"] + t[\"retweet_count\"] + 1}\n",
    "                tweets.append(tweet)\n",
    "                \n",
    "            # pos, neg, ntrl\n",
    "            sentiment = [0, 0, 0]\n",
    "            for tweet in tweets:\n",
    "                t = TextBlob(tweet[\"text\"])\n",
    "                if t.sentiment[0]>0:\n",
    "                   sentiment[0] += tweet[\"weight\"]\n",
    "                elif t.sentiment[0]<0:\n",
    "                   sentiment[1] += tweet[\"weight\"]\n",
    "                else:\n",
    "                   sentiment[2] += tweet[\"weight\"]\n",
    "                    \n",
    "            i = np.argmax(sentiment)\n",
    "            if(i == 0):\n",
    "                o = 1\n",
    "            elif(i == 1):\n",
    "                o = -1\n",
    "            else:\n",
    "                o = 0\n",
    "            \n",
    "            stock_sentiments[stock_name].append((date_str, o))\n",
    "\n",
    "for stock_name, sentiments in stock_sentiments.items():\n",
    "    sentiments.sort(key=lambda x: x[0])\n",
    "\n",
    "    first_date = sentiments[0][0]\n",
    "    last_date = sentiments[-1][0]\n",
    "    all_dates = date_range(first_date, last_date)\n",
    "\n",
    "    sentiment_dict = {date: sentiment for date, sentiment in sentiments}\n",
    "    completed_sentiments = []\n",
    "    \n",
    "    y = 0\n",
    "    for date in all_dates:\n",
    "        s = sentiment_dict.get(date, 0)\n",
    "        y += s\n",
    "        completed_sentiments.append((date, s, y))\n",
    "    \n",
    "    stock_sentiments[stock_name] = {date: {'Sentiment': s, 'Cum_Sentiment': y} for date, s, y in completed_sentiments}\n",
    "\n",
    "    output_file = f\"preprocessed-data/sentiment/{stock_name}.txt\"\n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        for date, s, y in completed_sentiments:\n",
    "            outfile.write(f\"{date} {s} {y}\\n\")\n",
    "\n",
    "print(\"Sentiment values added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b0440937-8341-482e-bf44-10ac6ea32297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added target and sentiment values to CSV files\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(\"../Dataset/price/raw/*.csv\"):\n",
    "    name = os.path.basename(file)\n",
    "    stock_name = name.split(\".\")[0]\n",
    "\n",
    "    if stock_name not in stock_sentiments:\n",
    "        continue\n",
    "\n",
    "    sentiment_data = stock_sentiments[stock_name]\n",
    "\n",
    "    with open(file, \"r\") as infile, open(\"preprocessed-data/input-data/\" + name, \"w\", newline='') as outfile:\n",
    "        counter = 0\n",
    "        seven_days_count = []\n",
    "        thirty_days_count = []\n",
    "        one_year_count = []\n",
    "        open_prices_7 = []\n",
    "        open_prices_30 = []\n",
    "        open_prices_365 = []\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "        \n",
    "        previous_open_price = None\n",
    "    \n",
    "        header = next(reader)\n",
    "        header_indices = {column_name: index for index, column_name in enumerate(header)}\n",
    "        date_index = header_indices.get('Date')\n",
    "        open_index = header_indices.get('Open')\n",
    "        close_index = header_indices.get('Close')\n",
    "        \n",
    "        new_header = header + [\n",
    "            \"Sentiment\",\n",
    "            \"Cum_sentiment\",\n",
    "            \"Seven_days_count\",\n",
    "            \"Thirty_days_count\",\n",
    "            \"One_year_count\",\n",
    "            \"7_day_SMA\",\n",
    "            \"30_day_SMA\",\n",
    "            \"365_day_SMA\",\n",
    "            \"Daily_Return\",\n",
    "            \"Target\"\n",
    "        ]\n",
    "        writer.writerow(new_header)\n",
    "\n",
    "        \n",
    "        for row in reader:\n",
    "            counter+=1\n",
    "            date_str = row[date_index]\n",
    "\n",
    "            try:\n",
    "                current_open_price = float(row[open_index])\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            open_prices_7.append(current_open_price)\n",
    "            open_prices_30.append(current_open_price)\n",
    "            open_prices_365.append(current_open_price)\n",
    "\n",
    "            if len(open_prices_7) > 7:\n",
    "                open_prices_7.pop(0)\n",
    "            if len(open_prices_30) > 30:\n",
    "                open_prices_30.pop(0)\n",
    "            if len(open_prices_365) > 365:\n",
    "                open_prices_365.pop(0)\n",
    "            \n",
    "            moving_average_7 = sum(open_prices_7) / len(open_prices_7) if len(open_prices_7) == 7 else None\n",
    "            moving_average_30 = sum(open_prices_30) / len(open_prices_30) if len(open_prices_30) == 30 else None\n",
    "            moving_average_365 = sum(open_prices_365) / len(open_prices_365) if len(open_prices_365) == 365 else None\n",
    "\n",
    "            if previous_open_price is not None:\n",
    "                daily_return = (current_open_price - previous_open_price) / previous_open_price\n",
    "            else:\n",
    "                daily_return = ''\n",
    "            \n",
    "            if previous_open_price is not None:\n",
    "                if current_open_price > previous_open_price:\n",
    "                    target = 1\n",
    "                else:\n",
    "                    target = 0\n",
    "                seven_days_count.append(target)\n",
    "                thirty_days_count.append(target)\n",
    "                one_year_count.append(target)\n",
    "            else:\n",
    "                target = None\n",
    "\n",
    "            ## Counting how many times the price has gone up during the last week, month or year\n",
    "            if len(seven_days_count) > 7:\n",
    "                seven_days_count.pop(0)\n",
    "            if len(thirty_days_count) > 30:\n",
    "                thirty_days_count.pop(0)\n",
    "            if len(one_year_count) > 365:\n",
    "                one_year_count.pop(0)\n",
    "\n",
    "            previous_open_price = current_open_price\n",
    "\n",
    "            sentiment_info = sentiment_data.get(date_str, {'Sentiment': 0, 'Cum_Sentiment': 0})\n",
    "            sentiment = sentiment_info['Sentiment']\n",
    "            cum_sentiment = sentiment_info['Cum_Sentiment']\n",
    "\n",
    "\n",
    "            new_row = row + [\n",
    "                sentiment,\n",
    "                cum_sentiment,\n",
    "                seven_days_count.count(1),\n",
    "                thirty_days_count.count(1),\n",
    "                one_year_count.count(1),\n",
    "                moving_average_7,\n",
    "                moving_average_30,\n",
    "                moving_average_365,\n",
    "                daily_return,\n",
    "                target\n",
    "            ]\n",
    "            \n",
    "            writer.writerow(new_row)\n",
    "    \n",
    "print('Added target and sentiment values to CSV files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661254d7-9a40-483e-b71a-d26162de687c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
